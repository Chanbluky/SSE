name: "sse_holonet_test"
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 0
    mean_file: "data/EmotiW_3_norm/EmotiW_3_norm_mean.binaryproto"
  }
  data_param {
    source: "examples/EmotiW_3_norm/EmotiW_3_norm_val_lmdb"
    batch_size: 128
    backend: LMDB
  }
}

layer {
  # 128x128x1->128x128x8
  name: "conv1_1/conv"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1/conv"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 3
    pad_w: 3
    kernel_h: 7
    kernel_w: 7
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv1_1/bn"
  type: "BatchNorm"
  bottom: "conv1_1/conv"
  top: "conv1_1/conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv1_1/neg"
  type: "Power"
  bottom: "conv1_1/conv"
  top: "conv1_1/neg"
  power_param {
    power: 1
    scale: -1.0
    shift: 1
  }
}
layer {
  name: "conv1_1/concat"
  type: "Concat"
  bottom: "conv1_1/conv"
  bottom: "conv1_1/neg"
  top: "conv1_1"
}
layer {
  name: "conv1_1/scale"
  type: "Scale"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 1.0
    decay_mult: 0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_1/relu"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  # 128x128x1->64x64x16 
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad: 0
  }
}
layer {
  name: "conv2_1/1/conv"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1/1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 12
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv2_1/1/bn"
  type: "BatchNorm"
  bottom: "conv2_1/1"
  top: "conv2_1/1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_1/1/bn_scale"
  type: "Scale"
  bottom: "conv2_1/1"
  top: "conv2_1/1"
  param {
    lr_mult: 1.0
    decay_mult: 0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1/1/relu"
  type: "ReLU"
  bottom: "conv2_1/1"
  top: "conv2_1/1"
}
layer {
  name: "conv2_1/2/conv"
  type: "Convolution"
  bottom: "conv2_1/1"
  top: "conv2_1/2/conv"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 12
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv2_1/2/bn"
  type: "BatchNorm"
  bottom: "conv2_1/2/conv"
  top: "conv2_1/2/conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_1/2/neg"
  type: "Power"
  bottom: "conv2_1/2/conv"
  top: "conv2_1/2/neg"
  power_param {
    power: 1
    scale: -1.0
    shift: 1
  }
}
layer {
  name: "conv2_1/2/concat"
  type: "Concat"
  bottom: "conv2_1/2/conv"
  bottom: "conv2_1/2/neg"
  top: "conv2_1/2"
}
layer {
  name: "conv2_1/2/scale"
  type: "Scale"
  bottom: "conv2_1/2"
  top: "conv2_1/2"
  param {
    lr_mult: 1.0
    decay_mult: 0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1/2/relu"
  type: "ReLU"
  bottom: "conv2_1/2"
  top: "conv2_1/2"
}
layer {
  name: "conv2_1/3/conv"
  type: "Convolution"
  bottom: "conv2_1/2"
  top: "conv2_1/3"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 32
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv2_1/3/bn"
  type: "BatchNorm"
  bottom: "conv2_1/3"
  top: "conv2_1/3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_1/3/bn_scale"
  type: "Scale"
  bottom: "conv2_1/3"
  top: "conv2_1/3"
  param {
    lr_mult: 1.0
    decay_mult: 0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1/proj"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1/proj"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 32
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv2_1/proj_bn"
  type: "BatchNorm"
  bottom: "conv2_1/proj"
  top: "conv2_1/proj"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_1/proj_bn_scale"
  type: "Scale"
  bottom: "conv2_1/proj"
  top: "conv2_1/proj"
  param {
    lr_mult: 1.0
    decay_mult: 0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_1"
  type: "Eltwise"
  bottom: "conv2_1/3"
  bottom: "conv2_1/proj"
  top: "conv2_1"
  eltwise_param {
    operation: SUM
    coeff: 1
    coeff: 1
  }
}
layer {
  name: "conv2_2/1/conv"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2/1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 12
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv2_2/1/bn"
  type: "BatchNorm"
  bottom: "conv2_2/1"
  top: "conv2_2/1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_2/1/bn_scale"
  type: "Scale"
  bottom: "conv2_2/1"
  top: "conv2_2/1"
  param {
    lr_mult: 1.0
    decay_mult: 0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2/1/relu"
  type: "ReLU"
  bottom: "conv2_2/1"
  top: "conv2_2/1"
}
layer {
  name: "conv2_2/2/conv"
  type: "Convolution"
  bottom: "conv2_2/1"
  top: "conv2_2/2/conv"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 12
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv2_2/2/bn"
  type: "BatchNorm"
  bottom: "conv2_2/2/conv"
  top: "conv2_2/2/conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_2/2/neg"
  type: "Power"
  bottom: "conv2_2/2/conv"
  top: "conv2_2/2/neg"
  power_param {
    power: 1
    scale: -1.0
    shift: 1
  }
}
layer {
  name: "conv2_2/2/concat"
  type: "Concat"
  bottom: "conv2_2/2/conv"
  bottom: "conv2_2/2/neg"
  top: "conv2_2/2"
}
layer {
  name: "conv2_2/2/scale"
  type: "Scale"
  bottom: "conv2_2/2"
  top: "conv2_2/2"
  param {
    lr_mult: 1.0
    decay_mult: 0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2/2/relu"
  type: "ReLU"
  bottom: "conv2_2/2"
  top: "conv2_2/2"
}
layer {
  name: "conv2_2/3/conv"
  type: "Convolution"
  bottom: "conv2_2/2"
  top: "conv2_2/3"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 32
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv2_2/3/bn"
  type: "BatchNorm"
  bottom: "conv2_2/3"
  top: "conv2_2/3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv2_2/3/bn_scale"
  type: "Scale"
  bottom: "conv2_2/3"
  top: "conv2_2/3"
  param {
    lr_mult: 1.0
    decay_mult: 0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv2_2/input"
  type: "Power"
  bottom: "conv2_1"
  top: "conv2_2/input"
  power_param {
    power: 1
    scale: 1
    shift: 1
  }
}
layer {
  name: "conv2_2"
  type: "Eltwise"
  bottom: "conv2_2/3"
  bottom: "conv2_2/input"
  top: "conv2_2"
  eltwise_param {
    operation: SUM
    coeff: 1
    coeff: 1
  }
}


layer {
  # 64x64x32->32x32x48
  name: "conv3_1/1/conv"
  type: "Convolution"
  bottom: "conv2_2"
  top: "conv3_1/1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 16
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 2
    stride_w: 2
  }
}
layer {
  name: "conv3_1/1/bn"
  type: "BatchNorm"
  bottom: "conv3_1/1"
  top: "conv3_1/1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_1/1/bn_scale"
  type: "Scale"
  bottom: "conv3_1/1"
  top: "conv3_1/1"
  param {
    lr_mult: 1.0
    decay_mult: 0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1/1/relu"
  type: "ReLU"
  bottom: "conv3_1/1"
  top: "conv3_1/1"
}
layer {
  name: "conv3_1/2/conv"
  type: "Convolution"
  bottom: "conv3_1/1"
  top: "conv3_1/2/conv"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 16
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv3_1/2/bn"
  type: "BatchNorm"
  bottom: "conv3_1/2/conv"
  top: "conv3_1/2/conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_1/2/neg"
  type: "Power"
  bottom: "conv3_1/2/conv"
  top: "conv3_1/2/neg"
  power_param {
    power: 1
    scale: -1.0
    shift: 1
  }
}
layer {
  name: "conv3_1/2/concat"
  type: "Concat"
  bottom: "conv3_1/2/conv"
  bottom: "conv3_1/2/neg"
  top: "conv3_1/2"
}
layer {
  name: "conv3_1/2/scale"
  type: "Scale"
  bottom: "conv3_1/2"
  top: "conv3_1/2"
  param {
    lr_mult: 1.0
    decay_mult: 0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1/2/relu"
  type: "ReLU"
  bottom: "conv3_1/2"
  top: "conv3_1/2"
}
layer {
  name: "conv3_1/3/conv"
  type: "Convolution"
  bottom: "conv3_1/2"
  top: "conv3_1/3"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 48
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv3_1/3/bn"
  type: "BatchNorm"
  bottom: "conv3_1/3"
  top: "conv3_1/3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_1/3/bn_scale"
  type: "Scale"
  bottom: "conv3_1/3"
  top: "conv3_1/3"
  param {
    lr_mult: 1.0
    decay_mult: 0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1/proj"
  type: "Convolution"
  bottom: "conv2_2"
  top: "conv3_1/proj"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 48
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 2
    stride_w: 2
  }
}
layer {
  name: "conv3_1/proj_bn"
  type: "BatchNorm"
  bottom: "conv3_1/proj"
  top: "conv3_1/proj"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_1/proj_bn_scale"
  type: "Scale"
  bottom: "conv3_1/proj"
  top: "conv3_1/proj"
  param {
    lr_mult: 1.0
    decay_mult: 0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_1"
  type: "Eltwise"
  bottom: "conv3_1/3"
  bottom: "conv3_1/proj"
  top: "conv3_1"
  eltwise_param {
    operation: SUM
    coeff: 1
    coeff: 1
  }
}

layer {
  name: "pool3_1"
  type: "Pooling"
  bottom: "conv3_1"
  top: "pool3_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}

layer {
  name: "conv_fc3_1"
  type: "Convolution"
  bottom: "pool3_1"
  top: "conv_fc3_1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param  {
    num_output: 1024
	kernel_size: 16
	stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
} 
layer {
  name: "conv_fc3_1/bn"
  type: "BatchNorm"
  bottom: "conv_fc3_1"
  top: "conv_fc3_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv_fc3_1/bn_scale"
  type: "Scale"
  bottom: "conv_fc3_1"
  top: "conv_fc3_1"
  param {
    lr_mult: 1.0
    decay_mult: 0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv_fc3_1/relu"
  type: "ReLU"
  bottom: "conv_fc3_1"
  top: "conv_fc3_1"
}
layer {
  name: "conv_fc3_1_1"
  type: "Convolution"
  bottom: "conv_fc3_1"
  top: "conv_fc3_1_1"
  param { lr_mult: 1.0  decay_mult: 1.0 }
  convolution_param {
    num_output: 14
	kernel_size: 1
	stride: 1
    weight_filler { type: "xavier" }
    bias_filler { type: "constant"  value: 0.1 }
  }
}
layer {  
   name: "pool_fc3_1_1"
   type: "Pooling" 
   bottom: "conv_fc3_1_1"  
   top: "pool_fc3_1_1"  
   pooling_param {  
      pool: AVE  
      kernel_h: 1
      kernel_w: 1 
      stride: 1 
      pad: 0 
  }  
}

layer {
  name: "flat_3_1"
  type: "Flatten"
  bottom: "pool_fc3_1_1"
  top: "flat_3_1"
}

layer {
  name: "loss3_1"
  type: "SoftmaxWithLoss"
  bottom: "flat_3_1"
  bottom: "label"
  top: "loss3_1"
}


layer {
  name: "conv3_2/1/conv"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2/1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 16
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv3_2/1/bn"
  type: "BatchNorm"
  bottom: "conv3_2/1"
  top: "conv3_2/1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_2/1/bn_scale"
  type: "Scale"
  bottom: "conv3_2/1"
  top: "conv3_2/1"
  param {
    lr_mult: 1.0
    decay_mult: 0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_2/1/relu"
  type: "ReLU"
  bottom: "conv3_2/1"
  top: "conv3_2/1"
}
layer {
  name: "conv3_2/2/conv"
  type: "Convolution"
  bottom: "conv3_2/1"
  top: "conv3_2/2/conv"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 16
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv3_2/2/bn"
  type: "BatchNorm"
  bottom: "conv3_2/2/conv"
  top: "conv3_2/2/conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_2/2/neg"
  type: "Power"
  bottom: "conv3_2/2/conv"
  top: "conv3_2/2/neg"
  power_param {
    power: 1
    scale: -1.0
    shift: 1
  }
}
layer {
  name: "conv3_2/2/concat"
  type: "Concat"
  bottom: "conv3_2/2/conv"
  bottom: "conv3_2/2/neg"
  top: "conv3_2/2"
}
layer {
  name: "conv3_2/2/scale"
  type: "Scale"
  bottom: "conv3_2/2"
  top: "conv3_2/2"
  param {
    lr_mult: 1.0
    decay_mult: 0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_2/2/relu"
  type: "ReLU"
  bottom: "conv3_2/2"
  top: "conv3_2/2"
}
layer {
  name: "conv3_2/3/conv"
  type: "Convolution"
  bottom: "conv3_2/2"
  top: "conv3_2/3"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 48
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv3_2/3/bn"
  type: "BatchNorm"
  bottom: "conv3_2/3"
  top: "conv3_2/3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv3_2/3/bn_scale"
  type: "Scale"
  bottom: "conv3_2/3"
  top: "conv3_2/3"
  param {
    lr_mult: 1.0
    decay_mult: 0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv3_2/input"
  type: "Power"
  bottom: "conv3_1"
  top: "conv3_2/input"
  power_param {
    power: 1
    scale: 1
    shift: 1
  }
}
layer {
  name: "conv3_2"
  type: "Eltwise"
  bottom: "conv3_2/3"
  bottom: "conv3_2/input"
  top: "conv3_2"
  eltwise_param {
    operation: SUM
    coeff: 1
    coeff: 1
  }
}

layer {
  name: "pool3_2"
  type: "Pooling"
  bottom: "conv3_2"
  top: "pool3_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}

layer {
  name: "conv_fc3_2"
  type: "Convolution"
  bottom: "pool3_2"
  top: "conv_fc3_2"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param  {
    num_output: 1024
	kernel_size: 16
	stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
} 
layer {
  name: "conv_fc3_2/bn"
  type: "BatchNorm"
  bottom: "conv_fc3_2"
  top: "conv_fc3_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv_fc3_2/bn_scale"
  type: "Scale"
  bottom: "conv_fc3_2"
  top: "conv_fc3_2"
  param {
    lr_mult: 1.0
    decay_mult: 0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv_fc3_2/relu"
  type: "ReLU"
  bottom: "conv_fc3_2"
  top: "conv_fc3_2"
}
layer {
  name: "conv_fc3_2_1"
  type: "Convolution"
  bottom: "conv_fc3_2"
  top: "conv_fc3_2_1"
  param { lr_mult: 1.0  decay_mult: 1.0 }
  convolution_param {
    num_output: 14
	kernel_size: 1
	stride: 1
    weight_filler { type: "xavier" }
    bias_filler { type: "constant"  value: 0.1 }
  }
}
layer {  
   name: "pool_fc3_2_1"
   type: "Pooling" 
   bottom: "conv_fc3_2_1"  
   top: "pool_fc3_2_1"  
   pooling_param {  
      pool: AVE  
      kernel_h: 1
      kernel_w: 1 
      stride: 1 
      pad: 0 
  }  
}

layer {
  name: "flat_3_2"
  type: "Flatten"
  bottom: "pool_fc3_2_1"
  top: "flat_3_2"
}

layer {
  name: "loss3_2"
  type: "SoftmaxWithLoss"
  bottom: "flat_3_2"
  bottom: "label"
  top: "loss3_2"
}

layer {
  name: "conv4_1/incep/0/conv"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv4_1/incep/0"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 24
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 2
    stride_w: 2
  }
}
layer {
  name: "conv4_1/incep/0/bn"
  type: "BatchNorm"
  bottom: "conv4_1/incep/0"
  top: "conv4_1/incep/0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_1/incep/0/bn_scale"
  type: "Scale"
  bottom: "conv4_1/incep/0"
  top: "conv4_1/incep/0"
  param {
    lr_mult: 1.0
    decay_mult: 0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1/incep/0/relu"
  type: "ReLU"
  bottom: "conv4_1/incep/0"
  top: "conv4_1/incep/0"
}
layer {
  name: "conv4_1/incep/1_reduce/conv"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv4_1/incep/1_reduce"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 16
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 2
    stride_w: 2
  }
}
layer {
  name: "conv4_1/incep/1_reduce/bn"
  type: "BatchNorm"
  bottom: "conv4_1/incep/1_reduce"
  top: "conv4_1/incep/1_reduce"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_1/incep/1_reduce/bn_scale"
  type: "Scale"
  bottom: "conv4_1/incep/1_reduce"
  top: "conv4_1/incep/1_reduce"
  param {
    lr_mult: 1.0
    decay_mult: 0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1/incep/1_reduce/relu"
  type: "ReLU"
  bottom: "conv4_1/incep/1_reduce"
  top: "conv4_1/incep/1_reduce"
}
layer {
  name: "conv4_1/incep/1_0/conv"
  type: "Convolution"
  bottom: "conv4_1/incep/1_reduce"
  top: "conv4_1/incep/1_0"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 32
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv4_1/incep/1_0/bn"
  type: "BatchNorm"
  bottom: "conv4_1/incep/1_0"
  top: "conv4_1/incep/1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_1/incep/1_0/bn_scale"
  type: "Scale"
  bottom: "conv4_1/incep/1_0"
  top: "conv4_1/incep/1_0"
  param {
    lr_mult: 1.0
    decay_mult: 0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1/incep/1_0/relu"
  type: "ReLU"
  bottom: "conv4_1/incep/1_0"
  top: "conv4_1/incep/1_0"
}
layer {
  name: "conv4_1/incep/2_reduce/conv"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv4_1/incep/2_reduce"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 12
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 2
    stride_w: 2
  }
}
layer {
  name: "conv4_1/incep/2_reduce/bn"
  type: "BatchNorm"
  bottom: "conv4_1/incep/2_reduce"
  top: "conv4_1/incep/2_reduce"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_1/incep/2_reduce/bn_scale"
  type: "Scale"
  bottom: "conv4_1/incep/2_reduce"
  top: "conv4_1/incep/2_reduce"
  param {
    lr_mult: 1.0
    decay_mult: 0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1/incep/2_reduce/relu"
  type: "ReLU"
  bottom: "conv4_1/incep/2_reduce"
  top: "conv4_1/incep/2_reduce"
}
layer {
  name: "conv4_1/incep/2_0/conv"
  type: "Convolution"
  bottom: "conv4_1/incep/2_reduce"
  top: "conv4_1/incep/2_0"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 16
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv4_1/incep/2_0/bn"
  type: "BatchNorm"
  bottom: "conv4_1/incep/2_0"
  top: "conv4_1/incep/2_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_1/incep/2_0/bn_scale"
  type: "Scale"
  bottom: "conv4_1/incep/2_0"
  top: "conv4_1/incep/2_0"
  param {
    lr_mult: 1.0
    decay_mult: 0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1/incep/2_0/relu"
  type: "ReLU"
  bottom: "conv4_1/incep/2_0"
  top: "conv4_1/incep/2_0"
}
layer {
  name: "conv4_1/incep/2_1/conv"
  type: "Convolution"
  bottom: "conv4_1/incep/2_0"
  top: "conv4_1/incep/2_1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 16
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv4_1/incep/2_1/bn"
  type: "BatchNorm"
  bottom: "conv4_1/incep/2_1"
  top: "conv4_1/incep/2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_1/incep/2_1/bn_scale"
  type: "Scale"
  bottom: "conv4_1/incep/2_1"
  top: "conv4_1/incep/2_1"
  param {
    lr_mult: 1.0
    decay_mult: 0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1/incep/2_1/relu"
  type: "ReLU"
  bottom: "conv4_1/incep/2_1"
  top: "conv4_1/incep/2_1"
}
layer {
  name: "conv4_1/incep/pool"
  type: "Pooling"
  bottom: "conv3_2"
  top: "conv4_1/incep/pool"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad: 0
  }
}
layer {
  name: "conv4_1/incep/poolproj/conv"
  type: "Convolution"
  bottom: "conv4_1/incep/pool"
  top: "conv4_1/incep/poolproj"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 32
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv4_1/incep/poolproj/bn"
  type: "BatchNorm"
  bottom: "conv4_1/incep/poolproj"
  top: "conv4_1/incep/poolproj"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_1/incep/poolproj/bn_scale"
  type: "Scale"
  bottom: "conv4_1/incep/poolproj"
  top: "conv4_1/incep/poolproj"
  param {
    lr_mult: 1.0
    decay_mult: 0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1/incep/poolproj/relu"
  type: "ReLU"
  bottom: "conv4_1/incep/poolproj"
  top: "conv4_1/incep/poolproj"
}
layer {
  name: "conv4_1/incep"
  type: "Concat"
  bottom: "conv4_1/incep/0"
  bottom: "conv4_1/incep/1_0"
  bottom: "conv4_1/incep/2_1"
  bottom: "conv4_1/incep/poolproj"
  top: "conv4_1/incep"
}
layer {
  name: "conv4_1/out/conv"
  type: "Convolution"
  bottom: "conv4_1/incep"
  top: "conv4_1/out"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    weight_filler {
      type: "xavier"
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
  }
}
layer {
  name: "conv4_1/out/bn"
  type: "BatchNorm"
  bottom: "conv4_1/out"
  top: "conv4_1/out"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_1/out/bn_scale"
  type: "Scale"
  bottom: "conv4_1/out"
  top: "conv4_1/out"
  param {
    lr_mult: 1.0
    decay_mult: 0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1/proj"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv4_1/proj"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 64
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 2
    stride_w: 2
  }
}
layer {
  name: "conv4_1/proj_bn"
  type: "BatchNorm"
  bottom: "conv4_1/proj"
  top: "conv4_1/proj"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv4_1/proj_bn_scale"
  type: "Scale"
  bottom: "conv4_1/proj"
  top: "conv4_1/proj"
  param {
    lr_mult: 1.0
    decay_mult: 0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv4_1"
  type: "Eltwise"
  bottom: "conv4_1/out"
  bottom: "conv4_1/proj"
  top: "conv4_1"
  eltwise_param {
    operation: SUM
    coeff: 1
    coeff: 1
  }
}
layer {
  name: "pool4_1"
  type: "Pooling"
  bottom: "conv4_1"
  top: "pool4_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}

layer {
  name: "conv_fc4_1"
  type: "Convolution"
  bottom: "pool4_1"
  top: "conv_fc4_1"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  param {
    lr_mult: 2.0
    decay_mult: 0.0
  }
  convolution_param  {
    num_output: 1024
	kernel_size: 8
	stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0.1
    }
  }
} 
layer {
  name: "conv_fc4_1/bn"
  type: "BatchNorm"
  bottom: "conv_fc4_1"
  top: "conv_fc4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
  }
}
layer {
  name: "conv_fc4_1/bn_scale"
  type: "Scale"
  bottom: "conv_fc4_1"
  top: "conv_fc4_1"
  param {
    lr_mult: 1.0
    decay_mult: 0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv_fc4_1/relu"
  type: "ReLU"
  bottom: "conv_fc4_1"
  top: "conv_fc4_1"
}
layer {
  name: "conv_fc4_1_1"
  type: "Convolution"
  bottom: "conv_fc4_1"
  top: "conv_fc4_1_1"
  param { lr_mult: 1.0  decay_mult: 1.0 }
  convolution_param {
    num_output: 14
	kernel_size: 1
	stride: 1
    weight_filler { type: "xavier" }
    bias_filler { type: "constant"  value: 0.1 }
  }
}
layer {  
   name: "pool_fc4_1_1"
   type: "Pooling" 
   bottom: "conv_fc4_1_1"  
   top: "pool_fc4_1_1"  
   pooling_param {  
      pool: AVE  
      kernel_h: 1
      kernel_w: 1 
      stride: 1 
      pad: 0 
  }  
}

layer {
  name: "flat_4_1"
  type: "Flatten"
  bottom: "pool_fc4_1_1"
  top: "flat_4_1"
}

layer {
  name: "loss4_1"
  type: "SoftmaxWithLoss"
  bottom: "flat_4_1"
  bottom: "label"
  top: "loss4_1"
}


### Loss
layer {
  name: "fc_cascade"
  type: "Concat"
  bottom: "flat_3_1"
  bottom: "flat_3_2"
  bottom: "flat_4_1"
  top: "fc_cascade"
}

layer {
  name: "fc_fused"
  type: "InnerProduct"
  bottom: "fc_cascade"
  top: "fc_fused"
  param { lr_mult: 1.0  decay_mult: 1.0 }
  inner_product_param {
    num_output: 7
    weight_filler { type: "xavier" }
    bias_filler { type: "constant"  value: 0.1 }
  }
}

layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc_fused"
  bottom: "label"
  top: "loss"
}

layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc_fused"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 1
  }
}
